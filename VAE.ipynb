{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO - function headers\n",
    "#TODO - upload calc proof of KL Divergence\n",
    "#TODO - implement dropout in encoder and decoder\n",
    "#TODO - implement loops for arbitrary geometries in encoder and decoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import flags\n",
    "import ops\n",
    "import data_utils\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers import l2_regularizer, fully_connected, flatten, batch_norm\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder():\n",
    "    \n",
    "    def __init__(self, image_shape, z_size, dtype=tf.float32):\n",
    "        \n",
    "        self.image_shape = image_shape # a list\n",
    "        self.dtype = dtype\n",
    "        self.z_size = z_size\n",
    "    \n",
    "    def encoder(self,\n",
    "                X,\n",
    "                init_depth=32,\n",
    "                dropout_keep_prob=0.5,\n",
    "                training=True):\n",
    "\n",
    "        assert X.get_shape().as_list()[1:] == list(self.image_shape), \"input shape (%s), ignoring batch_size, is different than expected shape %s\" % (X.get_shape().as_list()[1:] , list(self.image_shape))\n",
    "        assert X.dtype == self.dtype, \"Unmatching datatypes\"\n",
    "        \n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            \n",
    "            #The first layer takes in an input image, and does a 5x5 convolution with it\n",
    "            # this is then passed to a leaky relu\n",
    "            h1 = ops.conv(X,\n",
    "                         init_depth,\n",
    "                         kernel=[5,5],\n",
    "                         strides=[2,2],\n",
    "                         w_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                         regularizer=None,\n",
    "                         name=\"e_conv_1\")\n",
    "            \n",
    "            h1_a = ops.leaky_relu(h1, alpha=0.2)\n",
    "            \n",
    "            #if training and dropout_keep_prob > 0., do dropout\n",
    "            \n",
    "            h2 = ops.conv(h1_a,\n",
    "                         init_depth*2,\n",
    "                         kernel=[5,5],\n",
    "                         strides=[2,2],\n",
    "                         w_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                         regularizer=None,\n",
    "                         name=\"e_conv_2\")\n",
    "            \n",
    "            h2_a = ops.leaky_relu(h2, alpha=0.2)\n",
    "            \n",
    "            #this input is now split into two separate fully_connected networks, one to output the\n",
    "            # means, and one to output the standard deviations\n",
    "            flat_h2 = flatten(h2_a)\n",
    "            mu_out = fully_connected(flat_h2,\n",
    "                                    self.z_size,\n",
    "                                    activation_fn=None,\n",
    "                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                    weights_regularizer=None,\n",
    "                                    scope=\"e_fc_3_1\")\n",
    "            \n",
    "            sigma_out = fully_connected(flat_h2,\n",
    "                                    self.z_size,\n",
    "                                    activation_fn=None,\n",
    "                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                    weights_regularizer=None,\n",
    "                                    scope=\"e_fc_3_2\")\n",
    "            \n",
    "            return mu_out, sigma_out\n",
    "    \n",
    "    def decoder(self,\n",
    "                X,\n",
    "                init_depth=32,\n",
    "                dropout_keep_prob=0.5,\n",
    "                training=True):\n",
    "        \n",
    "        assert X.dtype == self.dtype, \"Unmatching datatypes\"\n",
    "        \n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            \n",
    "            batch_size = X.get_shape().as_list()[0]\n",
    "            \n",
    "            #layer gets us prepared for the right dimensions to do two convolved transposes by taking a look\n",
    "            #at the latent representation vector that was used to sample from the encoder outputs\n",
    "            h1 = fully_connected(X,\n",
    "                                (self.image_shape[0]//4) * (self.image_shape[1]//4) * init_depth,\n",
    "                                activation_fn=None,\n",
    "                                weights_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                weights_regularizer=None,\n",
    "                                scope=\"d_fc_1\")\n",
    "            h1_reshape = tf.reshape(h1, [batch_size, self.image_shape[0]//4, self.image_shape[1]//4, init_depth ])\n",
    "            h1_a = tf.nn.relu(h1_reshape)\n",
    "            \n",
    "            #Layer two is the convolutional transpose and another relu\n",
    "            h2 = ops.conv_transpose(h1_a,\n",
    "                                   [batch_size, self.image_shape[0]//2, self.image_shape[1]//2, init_depth//2],\n",
    "                                    kernel=[5,5],\n",
    "                                    strides=[2,2],\n",
    "                                    w_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                    regularizer=None,\n",
    "                                    name=\"d_conv_t_2\")\n",
    "            h2_a = tf.nn.relu(h2)\n",
    "            \n",
    "            #Layer two is the convolutional transpose and a sigmoid to give us pixels\n",
    "            h3 = ops.conv_transpose(h2_a,\n",
    "                                   [batch_size, self.image_shape[0], self.image_shape[1], self.image_shape[2]],\n",
    "                                    kernel=[5,5],\n",
    "                                    strides=[2,2],\n",
    "                                    w_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                    regularizer=None,\n",
    "                                    name=\"d_conv_t_3\")\n",
    "            return tf.sigmoid(h3)\n",
    "\n",
    "    \n",
    "    def train(self, train_X, batch_size, epochs):\n",
    "        \n",
    "        #TODO - migrate these elsewhere\n",
    "        # stick in __init__ via vars(self).update(kwargs) for param names passed in flags\n",
    "        # replace all these with self.these\n",
    "        v_lr_init = 0.001\n",
    "        v_lr_steps = 1000\n",
    "        v_lr_decay = 1.0\n",
    "        v_lr_min = 0.00001\n",
    "        momentum = 0.9\n",
    "        v_min_grad = -1.0\n",
    "        v_max_grad = 1.0\n",
    "\n",
    "        reg_loss_lambda = 0.001\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "         #Create placeholder inputs for images, and separate the discriminator loss terms so that\n",
    "        # we can investigate them separately\n",
    "        assert list(train_X.shape[1:]) == list(self.image_shape), \"Training set image size does not match expected class image size\"\n",
    "        \n",
    "        #each training iteration makes use of training images and a random vector\n",
    "        X_tr = tf.placeholder(self.dtype, shape=[batch_size] + list(self.image_shape) )\n",
    "        \n",
    "        #random noise\n",
    "        z_sample = tf.placeholder(self.dtype, shape=[batch_size, self.z_size])\n",
    "        \n",
    "        #get unit gaussian from encoder network given the training images\n",
    "        z_mean, z_std = self.encoder(X_tr)\n",
    "\n",
    "        #Reparameterization - \n",
    "        #transform the sampled inputs by the mean and std vectors to get a sampled latent representation\n",
    "        # in this way, we still have a differentiable and deterministic model, with injected stochasticity through\n",
    "        # the random gaussian noise.\n",
    "        z_latent = z_mean + (z_std *  z_sample) #these are all tensorflow tensors\n",
    "                \n",
    "        #generate images from decoder\n",
    "        image_out = self.decoder(z_latent)\n",
    "        \n",
    "        #define a loss function based upon the output image.\n",
    "        # the goal is to maximize the log-likelihood of the data under the model params,\n",
    "        # that is p(x | theta_enc, theta_dec)\n",
    "        #\n",
    "        # We need to minimize -L, given that L is equal to the following\n",
    "        # L(ϕ,θ;x) = E_z∼q_ϕ(z|x) [log(p_θ(x|z))]  −  KL-Divergence (q_ϕ (z|x) || p_θ (z))\n",
    "        #\n",
    "        #\n",
    "        # The first term is the reconstruction error. How close the output to the input\n",
    "        # In other words, what is the log likelihood of output x-hat given latent distribution z\n",
    "        # This is easy, because we have a perfect function for this. CROSS ENTROPY!\n",
    "        image_reconstruction_loss = ops.binary_cross_entropy(image_out, X_tr, name=\"reconstruction_loss\")\n",
    "        \n",
    "        #the second term is the latent loss.\n",
    "        # this means the kullback liebler divergece between the latent space representation\n",
    "        # probability distribution and our prior.\n",
    "        # in the equation above, q_ϕ (z|x) is the output of the encoder, and p_θ (z) is the continuous prior, a unit gaussian\n",
    "        # this will give smooth interpolation\n",
    "        \n",
    "        # Here, we can use the analytical integration techniques of https://arxiv.org/pdf/1312.6114.pdf (appendix B)\n",
    "        # − KL-Divergence (q_ϕ (z|x) || p_θ (z)) = integral [q_θ(z) (log p_θ(z) - log q_θ(z))] dz\n",
    "        # - this will allow us to calculate this divergence using only the mu and sigma terms from our encoder\n",
    "        # - a nice transformation that can run fast and give the correct result\n",
    "        latent_kl_divergence_loss = ops.unit_gaussian_kl_divergence(z_mean, z_std)\n",
    "                \n",
    "        #TODO - regularization loss here if it is wanted\n",
    "        \n",
    "        loss = tf.reduce_mean(image_reconstruction_loss + latent_kl_divergence_loss)\n",
    "        \n",
    "        #use an exponentially-decaying learning rate\n",
    "        v_lr = tf.maximum(v_lr_min, tf.train.exponential_decay(v_lr_init, global_step, v_lr_steps, v_lr_decay, staircase=True))\n",
    "        \n",
    "        #adam optimizers work best for GAN's and VAE's\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=v_lr, beta1=momentum)\n",
    "        \n",
    "        #clip the gradients and apply them\n",
    "        grads_vars = opt.compute_gradients(loss)\n",
    "        grads_clipped = [(tf.clip_by_value(g, v_min_grad, v_max_grad), v) for g, v in grads_vars]\n",
    "        train_op = opt.apply_gradients(grads_clipped, global_step=global_step)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            self.sess = sess\n",
    "            report_frequency = None #steps\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            print(\"Initialized session variables\")\n",
    "\n",
    "            iterations = int(train_X.shape[0] / batch_size)\n",
    "            \n",
    "            epoch_rec_losses = []\n",
    "            epoch_kl_losses = []\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                \n",
    "                #shuffle data per epoch\n",
    "                print(\"Epoch %d / %d now training...\" % (epoch+1, epochs))\n",
    "                rec_losses = []\n",
    "                kl_losses = []\n",
    "                \n",
    "                shuf = np.random.permutation(train_X.shape[0])\n",
    "                train_X = train_X[shuf]\n",
    "\n",
    "                for i in range(iterations):\n",
    "                    \n",
    "                    #next batch, TODO - remove overflow protection here\n",
    "                    try:\n",
    "                        x = train_X[ i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "                    except IndexError:\n",
    "                        break\n",
    "                    \n",
    "                    #get gaussian noise with which to use in sampling the latent vector from the encoder\n",
    "                    noise = np.random.normal(size=[batch_size, self.z_size])\n",
    "                    \n",
    "                    #run the network. wahoo! separate the losses so we can track them\n",
    "                    rec_loss, kl_loss, _, total_loss = sess.run([image_reconstruction_loss, latent_kl_divergence_loss, train_op, loss], {X_tr: x, z_sample:noise})\n",
    "                    \n",
    "                    rec_losses.append(np.mean(rec_loss))\n",
    "                    kl_losses.append(np.mean(kl_loss))\n",
    "                    \n",
    "                    if report_frequency and i+1 % report_frequency == 0:\n",
    "                        print(\"Epoch step %d - Rec-Loss: %f\\t KL-Loss:%f\") % (i+1, np.mean(rec_loss), np.mean(kl_loss))\n",
    "                \n",
    "                print(\"Epoch %d - Avg Rec-Loss: %f\\t Avg KL-Loss:%f\") % (i+1, np.mean(rec_losses), np.mean(kl_losses))\n",
    "                epoch_rec_losses.append(np.mean(rec_losses))\n",
    "                epoch_kl_losses.append(np.mean(kl_losses))\n",
    "                \n",
    "                print(\"Generated sample images from last batch of epoch:\")\n",
    "                noise2=np.random.normal(size=[batch_size, self.z_size])\n",
    "                gen_img = sess.run(image_out, {X_tr: x, z_sample: noise2})\n",
    "                self.show_samples(gen_img)\n",
    "            \n",
    "            self.show_losses(epoch_rec_losses, epoch_kl_losses)\n",
    "\n",
    "    def show_samples(self, samples, n=25):\n",
    "        \n",
    "        sq_s = np.sqrt(n)\n",
    "        assert samples.shape[0] >= n, \"Num samples (%d) is larger than the number of samples passed to show_samples (%d)\" % (n, samples.shape[0])\n",
    "        assert round(sq_s)==sq_s, \"Expected to show samples in an nxn grid. Pass a perfect square less than the sample size as n\"\n",
    "        sq_s = int(sq_s)\n",
    "        \n",
    "        gs = gridspec.GridSpec(sq_s, 2*sq_s)\n",
    "        gs.update(wspace=0.2, hspace=0.2)\n",
    "        \n",
    "        for idx, sample in enumerate(samples):\n",
    "            if idx > n-1:\n",
    "                break\n",
    "            ax = plt.subplot(gs[(idx % sq_s), int(idx / sq_s)])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(np.squeeze(sample), cmap='Greys_r')\n",
    "        plt.show()\n",
    "        \n",
    "    def show_losses(self, d_losses, g_losses):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Load the Dataset\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "batch_size = FLAGS.batch_size\n",
    "\n",
    "(train_X, train_y), (_,_) = data_utils.load_dataset(FLAGS.dataset)\n",
    "shuf = np.random.permutation(train_X.shape[0])\n",
    "train_X = train_X[shuf]\n",
    "train_y = train_y[shuf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_VAE = VariationalAutoEncoder( train_X.shape[1:], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized session variables\n",
      "Epoch 1 / 500 now training...\n",
      "Epoch 468 - Avg Rec-Loss: 176.931046\t Avg KL-Loss:16.353476\n",
      "Generated sample images from last batch of epoch:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALkAAADlCAYAAAAP4VbQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8X8V/qpoJT6X0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81942c7ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 500 now training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d6aa32e17c00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_VAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-dbe08b02bb8b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_X, batch_size, epochs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0;31m#run the network. wahoo! separate the losses so we can track them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                     \u001b[0mrec_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_reconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_kl_divergence_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0mrec_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_VAE.train(train_X, batch_size, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
